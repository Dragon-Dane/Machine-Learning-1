1
Name:	BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
Link:	https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional
Code:	https://vimeo.com/365139010

2
Name:	ALBERT: ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
Link:	https://iclr.cc/virtual_2020/poster_H1eA7AEtvS.html
Code:	https://github.com/google-research/ALBERT

